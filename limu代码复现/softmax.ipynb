{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "(就像我们从零开始实现线性回归一样，) 我们认为softmax回归也是重要的基础，因此(你应该知道实现softmax回归的细节)。 本节我们将使用刚刚在 :numref:sec_fashion_mnist中引入的Fashion-MNIST数据集， 并设置数据迭代器的批量大小为256。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01md2l\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m  torch  \u001B[38;5;28;01mas\u001B[39;00m d2l\n\u001B[0;32m      4\u001B[0m batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m\n\u001B[1;32m----> 5\u001B[0m train_iter,test_iter \u001B[38;5;241m=\u001B[39m \u001B[43md2l\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_data_fashion_mnist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\d2l\\torch.py:216\u001B[0m, in \u001B[0;36mload_data_fashion_mnist\u001B[1;34m(batch_size, resize)\u001B[0m\n\u001B[0;32m    214\u001B[0m     trans\u001B[38;5;241m.\u001B[39minsert(\u001B[38;5;241m0\u001B[39m, transforms\u001B[38;5;241m.\u001B[39mResize(resize))\n\u001B[0;32m    215\u001B[0m trans \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose(trans)\n\u001B[1;32m--> 216\u001B[0m mnist_train \u001B[38;5;241m=\u001B[39m \u001B[43mtorchvision\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFashionMNIST\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[43m    \u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../data\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrans\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m mnist_test \u001B[38;5;241m=\u001B[39m torchvision\u001B[38;5;241m.\u001B[39mdatasets\u001B[38;5;241m.\u001B[39mFashionMNIST(\n\u001B[0;32m    219\u001B[0m     root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data\u001B[39m\u001B[38;5;124m\"\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, transform\u001B[38;5;241m=\u001B[39mtrans, download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (data\u001B[38;5;241m.\u001B[39mDataLoader(mnist_train, batch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    221\u001B[0m                         num_workers\u001B[38;5;241m=\u001B[39mget_dataloader_workers()),\n\u001B[0;32m    222\u001B[0m         data\u001B[38;5;241m.\u001B[39mDataLoader(mnist_test, batch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    223\u001B[0m                         num_workers\u001B[38;5;241m=\u001B[39mget_dataloader_workers()))\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:99\u001B[0m, in \u001B[0;36mMNIST.__init__\u001B[1;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[1;32m---> 99\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_exists():\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset not found. You can use download=True to download it\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:187\u001B[0m, in \u001B[0;36mMNIST.download\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 187\u001B[0m     \u001B[43mdownload_and_extract_archive\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload_root\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmd5\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmd5\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m URLError \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[0;32m    189\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to download (trying next):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00merror\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\utils.py:446\u001B[0m, in \u001B[0;36mdownload_and_extract_archive\u001B[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001B[0m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m filename:\n\u001B[0;32m    444\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(url)\n\u001B[1;32m--> 446\u001B[0m \u001B[43mdownload_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload_root\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmd5\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    448\u001B[0m archive \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(download_root, filename)\n\u001B[0;32m    449\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marchive\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mextract_root\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\utils.py:156\u001B[0m, in \u001B[0;36mdownload_url\u001B[1;34m(url, root, filename, md5, max_redirect_hops)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m url \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m to \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m fpath)\n\u001B[1;32m--> 156\u001B[0m     \u001B[43m_urlretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (urllib\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mURLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m url[:\u001B[38;5;241m5\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\utils.py:50\u001B[0m, in \u001B[0;36m_urlretrieve\u001B[1;34m(url, filename, chunk_size)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_urlretrieve\u001B[39m(url: \u001B[38;5;28mstr\u001B[39m, filename: \u001B[38;5;28mstr\u001B[39m, chunk_size: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m32\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39murlopen(urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mRequest(url, headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m: USER_AGENT})) \u001B[38;5;28;01mas\u001B[39;00m response:\n\u001B[1;32m---> 50\u001B[0m         \u001B[43m_save_response_content\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlength\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlength\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\utils.py:39\u001B[0m, in \u001B[0;36m_save_response_content\u001B[1;34m(content, destination, length)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_save_response_content\u001B[39m(\n\u001B[0;32m     34\u001B[0m     content: Iterator[\u001B[38;5;28mbytes\u001B[39m],\n\u001B[0;32m     35\u001B[0m     destination: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m     36\u001B[0m     length: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     37\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     38\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(destination, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m fh, tqdm(total\u001B[38;5;241m=\u001B[39mlength) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m---> 39\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m content:\n\u001B[0;32m     40\u001B[0m             \u001B[38;5;66;03m# filter out keep-alive new chunks\u001B[39;00m\n\u001B[0;32m     41\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunk:\n\u001B[0;32m     42\u001B[0m                 \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\utils.py:50\u001B[0m, in \u001B[0;36m_urlretrieve.<locals>.<lambda>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_urlretrieve\u001B[39m(url: \u001B[38;5;28mstr\u001B[39m, filename: \u001B[38;5;28mstr\u001B[39m, chunk_size: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m32\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39murlopen(urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mRequest(url, headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m: USER_AGENT})) \u001B[38;5;28;01mas\u001B[39;00m response:\n\u001B[1;32m---> 50\u001B[0m         _save_response_content(\u001B[38;5;28miter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m), filename, length\u001B[38;5;241m=\u001B[39mresponse\u001B[38;5;241m.\u001B[39mlength)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\http\\client.py:463\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    461\u001B[0m     \u001B[38;5;66;03m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[0;32m    462\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(amt)\n\u001B[1;32m--> 463\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    464\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b)[:n]\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[0;32m    465\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    466\u001B[0m     \u001B[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[0;32m    467\u001B[0m     \u001B[38;5;66;03m# and self.chunked\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\http\\client.py:507\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    502\u001B[0m         b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmemoryview\u001B[39m(b)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength]\n\u001B[0;32m    504\u001B[0m \u001B[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[0;32m    506\u001B[0m \u001B[38;5;66;03m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[1;32m--> 507\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m n \u001B[38;5;129;01mand\u001B[39;00m b:\n\u001B[0;32m    509\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[0;32m    510\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[0;32m    511\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist((batch_size))\n",
    "#加载数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 初始化模型参数\n",
    "\n",
    "和之前线性回归的例子一样，这里的每个样本都将用固定长度的向量表示。\n",
    "原始数据集中的每个样本都是$28 \\times 28$的图像。\n",
    "在本节中，我们[**将展平每个图像，把它们看作长度为784的向量。**]\n",
    "在后面的章节中，我们将讨论能够利用图像空间结构的特征，\n",
    "但现在我们暂时只把每个像素位置看作一个特征。\n",
    "\n",
    "回想一下，在softmax回归中，我们的输出与类别一样多。\n",
    "(**因为我们的数据集有10个类别，所以网络输出维度为10**)。\n",
    "因此，权重将构成一个$784 \\times 10$的矩阵，\n",
    "偏置将构成一个$1 \\times 10$的行向量。\n",
    "与线性回归一样，我们将使用正态分布初始化我们的权重`W`，偏置初始化为0。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_inputs = 784  #按像素拉成向量\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义softmax操作\n",
    "\n",
    "在实现softmax回归模型之前，我们简要回顾一下`sum`运算符如何沿着张量中的特定维度工作。\n",
    "如 :numref:`subseq_lin-alg-reduction`和\n",
    " :numref:`subseq_lin-alg-non-reduction`所述，\n",
    " [**给定一个矩阵`X`，我们可以对所有元素求和**]（默认情况下）。\n",
    " 也可以只求同一个轴上的元素，即同一列（轴0）或同一行（轴1）。\n",
    " 如果`X`是一个形状为`(2, 3)`的张量，我们对列进行求和，\n",
    " 则结果将是一个具有形状`(3,)`的向量。\n",
    " 当调用`sum`运算符时，我们可以指定保持在原始张量的轴数，而不折叠求和的维度。\n",
    " 这将产生一个具有形状`(1, 3)`的二维张量。\n",
    "eg:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "X.sum(0, keepdim=True), X.sum(1, keepdim=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "回想一下，[**实现softmax**]由三个步骤组成：\n",
    "\n",
    "1. 对每个项求幂（使用`exp`）；\n",
    "1. 对每一行求和（小批量中每个样本是一行），得到每个样本的规范化常数；\n",
    "1. 将每一行除以其规范化常数，确保结果的和为1。\n",
    "\n",
    "在查看代码之前，我们回顾一下这个表达式：\n",
    "\n",
    "(**\n",
    "$$\n",
    "\\mathrm{softmax}(\\mathbf{X})_{ij} = \\frac{\\exp(\\mathbf{X}_{ij})}{\\sum_k \\exp(\\mathbf{X}_{ik})}.\n",
    "$$\n",
    "**)\n",
    "\n",
    "分母或规范化常数，有时也称为*配分函数*（其对数称为对数-配分函数）。\n",
    "该名称来自[统计物理学](https://en.wikipedia.org/wiki/Partition_function_(statistical_mechanics))中一个模拟粒子群分布的方程。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition  #运用广播机制"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "正如你所看到的，对于任何随机输入，[**我们将每个元素变成一个非负数。\n",
    "此外，依据概率原理，每行总和为1**]。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义模型\n",
    "\n",
    "定义softmax操作后，我们可以[**实现softmax回归模型**]。\n",
    "下面的代码定义了输入如何通过网络映射到输出。\n",
    "注意，将数据传递到模型之前，我们使用`reshape`函数将每张原始图像展平为向量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W)\n",
    "    + b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 定义损失函数\n",
    "\n",
    "接下来，我们实现 :numref:`sec_softmax`中引入的交叉熵损失函数。\n",
    "这可能是深度学习中最常见的损失函数，因为目前分类问题的数量远远超过回归问题的数量。\n",
    "\n",
    "回顾一下，交叉熵采用真实标签的预测概率的负对数似然。\n",
    "这里我们不使用Python的for循环迭代预测（这往往是低效的），\n",
    "而是通过一个运算符选择所有元素。\n",
    "下面，我们[**创建一个数据样本`y_hat`，其中包含2个样本在3个类别的预测概率，\n",
    "以及它们对应的标签`y`。**]\n",
    "有了`y`，我们知道在第一个样本中，第一类是正确的预测；\n",
    "而在第二个样本中，第三类是正确的预测。\n",
    "然后(**使用`y`作为`y_hat`中概率的索引**)，\n",
    "我们选择第一个样本中第一个类的概率和第二个样本中第三个类的概率。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.5000])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([0, 2])\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "print(y_hat[[0, 1], y])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3229496334.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [6]\u001B[1;36m\u001B[0m\n\u001B[1;33m    def cross_entropy(y_hat,y):\u001B[0m\n\u001B[1;37m                               ^\u001B[0m\n\u001B[1;31mIndentationError\u001B[0m\u001B[1;31m:\u001B[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#交叉熵\n",
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])\n",
    "cross_entropy(y_hat, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 分类精度\n",
    "\n",
    "给定预测概率分布`y_hat`，当我们必须输出硬预测（hard prediction）时，\n",
    "我们通常选择预测概率最高的类。\n",
    "许多应用都要求我们做出选择。如Gmail必须将电子邮件分类为“Primary（主要邮件）”、\n",
    "“Social（社交邮件）”、“Updates（更新邮件）”或“Forums（论坛邮件）”。\n",
    "Gmail做分类时可能在内部估计概率，但最终它必须在类中选择一个。\n",
    "\n",
    "当预测与标签分类`y`一致时，即是正确的。\n",
    "分类精度即正确预测数量与总预测数量之比。\n",
    "虽然直接优化精度可能很困难（因为精度的计算不可导），\n",
    "但精度通常是我们最关心的性能衡量标准，我们在训练分类器时几乎总会关注它。\n",
    "\n",
    "为了计算精度，我们执行以下操作。\n",
    "首先，如果`y_hat`是矩阵，那么假定第二个维度存储每个类的预测分数。\n",
    "我们使用`argmax`获得每行中最大元素的索引来获得预测类别。\n",
    "然后我们[**将预测类别与真实`y`元素进行比较**]。\n",
    "由于等式运算符“`==`”对数据类型很敏感，\n",
    "因此我们将`y_hat`的数据类型转换为与`y`的数据类型一致。\n",
    "结果是一个包含0（错）和1（对）的张量。\n",
    "最后，我们求和会得到正确预测的数量。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def accuracy(y_hat ,y):  #@save\n",
    "     \"\"\"计算预测正确的数量\"\"\"\n",
    "     if len(y_hat.shape) > 1 and y_hat.shape[1]>1:\n",
    "         y_hat = y_hat.argmax(aixs=1)  #概率最大的\n",
    "     cmp = y_hat.type(y.dtype) ==y  #类型\n",
    "     return  float(cmp.type(y.dtype).sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们将继续使用之前定义的变量`y_hat`和`y`分别作为预测的概率分布和标签。\n",
    "可以看到，第一个样本的预测类别是2（该行的最大元素为0.6，索引为2），这与实际标签0不一致。\n",
    "第二个样本的预测类别是2（该行的最大元素为0.5，索引为2），这与实际标签2一致。\n",
    "因此，这两个样本的分类精度率为0.5。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy(y_hat,y)/len(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "同样，对于任意数据迭代器`data_iter`可访问的数据集，\n",
    "[**我们可以评估在任意模型`net`的精度**]。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net,data_iter): #@save\n",
    "    \"\"\"计算精度\"\"\"\n",
    "    if isinstance(net,torch.nn.Module):\n",
    "        net.eval();    #将模型设置为评估模式\n",
    "    metric = Accumulator(2)     # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X , y in data_iter:\n",
    "            metric.add(accuracy(net(X),y),y.numel())\n",
    "        return metric[0] / metric[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "这里定义一个实用程序类`Accumulator`，用于对多个变量进行累加。\n",
    "在上面的`evaluate_accuracy`函数中，\n",
    "我们在(**`Accumulator`实例中创建了2个变量，\n",
    "分别用于存储正确预测的数量和预测的总数量**)。\n",
    "当我们遍历数据集时，两者都将随着时间的推移而累加。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Accumulator : #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self,n):  #构造\n",
    "        self.data = [0.0]*n\n",
    "    def add(self,*args):\n",
    "        self.data+=[a+float(b) for a,b in zip(self.data,args)]\n",
    "    def reset(self):\n",
    "        self"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}